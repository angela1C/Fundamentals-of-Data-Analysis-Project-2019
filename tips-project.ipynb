{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Data Analysis Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://pandas.pydata.org/_static/pandas_logo.png\" alt =\"pandas_logo\" style=\"height:100px\" align=\"right\"/>\n",
    "<img src = \"https://seaborn.pydata.org/_static/scatterplot_matrix_thumb.png?v=0.9.0\" alt = \"seaborn\" style=\"width:150px\" align=\"left\"/>\n",
    "<img src =\"https://upload.wikimedia.org/wikipedia/commons/3/38/Jupyter_logo.svg\" alt =\"Jupyter logo\" width=\"150\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>\n",
    "# Project Overview\n",
    "\n",
    "This project concerns the well-known tips dataset and the Python packages **seaborn** and **jupyter**. \n",
    "The project is broken into three parts, as follows.\n",
    "\n",
    "1. Description: Descriptive Statistics and plots to describe the tips dataset.\n",
    "This sections provides a summary of the tips dataset using summary statistics and plots.\n",
    "\n",
    "2. Regression: Is there a relationship between the total bill and tip amount?\n",
    "This sections discusses and analyses the relationship, if any between the total bill amount and tip together with an explantion of the analysis.\n",
    "\n",
    "3. Analyse: Look at relationship between the variables within the dataset.\n",
    "Where section 2 looks at the relationship between total bill amount and the tip amount, this section investigate what relationships exist between all of the variables with interesting relationships highlighted and discussed. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>\n",
    "\n",
    "# Table of contents\n",
    "- [Project Overview](#overview)   \n",
    "- [About this notebook](#notebook)\n",
    "    - [Project plan](#plan)\n",
    "    - [Jupyter Notebook](#notebook)\n",
    "    - [Python Libraries](#libraries)\n",
    "    - [Downloading and running the code](#running)\n",
    "- [Part 1: Descriptive Statistics and plots to describe the tips dataset.](#part1)\n",
    "    - [The tips dataset](#tipsdataset)  \n",
    "    - [Loading / Reading in the dataset](#loading)    \n",
    "    - [Exploring the dataset](#exploring)  \n",
    "    - [Summary Statistics](#statistics)  \n",
    "    - [Visualising the dataset using plots](#visualise)\n",
    "- [Part 2 Regression: Discuss and analyse whether there is a relationship between the total bill and tip amount.](#part2)\n",
    "- [Part 3 Analyse: Analyse the relationships between the variables within the dataset](#part3)\n",
    "- [References](#references)  \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## project plan - remove later!\n",
    "<a id=\"plan\"></a>\n",
    "\n",
    "### Project Instructions\n",
    "As per the attached [Project Instructions]('Instructions.pdf'), this assessment concerns the tips dataset and the Python packages seaborn and jupyter. The project is broken into three parts, as follows.\n",
    "\n",
    "(30%) **Description**: Create a git repository and make it available online for the lecturer to clone. The repository should contain all your work for this assessment. Within the repository, create a jupyter notebook that uses descriptive statistics and plots to describe the tips dataset. \n",
    "*marked based on Good summary of the dataset, repository well laid-out and organised. Reasonable commits to the repository.*\n",
    "\n",
    "(30%) **Regression**: To the above jupyter notebook add a section that discusses and analyses whether there is a relationship between the total bill and tip amount.\n",
    "*marked based on Good analysis of the relationship between total bill and tip, with good explanations of the analysis.*\n",
    "(40%) **Analyse**: Again using the same notebook, analyse the relationship between the variables within the dataset. You are free to interpret this as you wish — for example, you may analyse all pairs of variables, or select a subset and analyse those. \n",
    "*marked based on Reasonable work investigating the relationship between the variables, with interesting relationships highlighted and discussed.*\n",
    "\n",
    "### 1. Description.\n",
    "- Descriptive Statistics using pandas functions such as `describe`\n",
    "- seaborn plots to show boxplots which visualise the main statistics from the `describe` function such as mean, median, lower and upper quartiles and interquartile ranges. \n",
    "- look at other seaborn plots that summarise the dataset\n",
    "\n",
    "### 2. Regression\n",
    "- look at plots first to see what the trends are between total bill amount and tip amount.\n",
    "- **discuss** and **analyse** whether there is a relationship.\n",
    "- provide a **good analysis** of the this relationship backed up by good explanations of this analysis.\n",
    "\n",
    "### 3. Analyse the relationships between the variables within the dataset\n",
    "- should see from previous steps any obvious relationships and explore these in more detail.\n",
    "- highlight interesting relationships between variables and discuss these in more detail. \n",
    "\n",
    "### 4. References\n",
    "- Keep reference list up to date as I go through the project. Look into better ways to referencing rather than adding throughout the document using reference style links as per [Markdown Guide](https://www.markdownguide.org/basic-syntax/#reference-style-links) which is not this way!\n",
    "\n",
    "### 5. Set up the relevant sections or parts before going any further!\n",
    "\n",
    "### 6. Refer to project instructions pdf to ensure I am keeping on track and not going off on a tangent.\n",
    "\n",
    "summarised above.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# About this notebook and python libraries used in it.\n",
    "<a id=\"notebook\"></a>\n",
    "\n",
    "For this project I will be using the **pandas**,  **seaborn** and **matplotlib.pyplot** packages which are imported using the conventionally used aliases of **pd** for **pandas**, **sn** for **seaborn** and the **matplotlib.pyplot** as **plt**. I may also be using NumPy. \n",
    "\n",
    "[Seaborn](https://seaborn.pydata.org) is a Python data visualization library for making attractive and informative statistical graphics in Python.  There is a website <https://seaborn.pydata.or> dedicated to showing the user how to use the seaborn library and I will be referring to this throughout this project. \n",
    " \n",
    "According to the [introduction to seaborn](https://seaborn.pydata.org/introduction.html#an-introduction-to-seaborn) on this website, seaborn is built on top of matplotlib and closely integrated with pandas data structures and among its features offers a 'dataset-oriented API for examining relationships between multiple variables, specialized support for using categorical variables to show observations or aggregate statistics... automatic estimation and plotting of linear regression models for different kinds dependent variables. Seaborn aims to make visualization a central part of exploring and understanding data. Its dataset-oriented plotting functions operate on dataframes and arrays containing whole datasets and internally perform the necessary semantic mapping and statistical aggregation to produce informative plots.'.\n",
    "All very relevent to this project!\n",
    "\n",
    "\n",
    "[pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/overview.html)\n",
    "\n",
    ">pandas is a Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real world data analysis in Python. Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis / manipulation tool available in any language. It is already well on its way toward this goal.\n",
    "\n",
    "  \n",
    "[jupyter]()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version 1.16.2 pandas version  0.24.2 seaborn version 0.9.0\n"
     ]
    }
   ],
   "source": [
    "## import libraries\n",
    "\n",
    "# import libraries using common alias names\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#np.version.version  # check what version of packages are installed.\n",
    "print(\"NumPy version\",np.__version__, \"pandas version \",pd.__version__, \"seaborn version\",sns.__version__  )  # '1.16.2'\n",
    "\n",
    "#np.set_printoptions(formatter={'float': lambda x: \"{0:6.3f}\".format(x)})\n",
    "np.set_printoptions(precision=4)  # set floating point precision to 4\n",
    "np.set_printoptions(threshold=5) # summarise long arrays\n",
    "np.set_printoptions(suppress=True) # to suppress small results\n",
    "\n",
    "pd.options.display.max_rows=8 # set options to display max number of rows\n",
    "\n",
    "# To display all the output in each cell instead of just the statement, run these two lines\n",
    "#from IPython.core.interactiveshell import InteractiveShell\n",
    "#InteractiveShell.ast_node_interactivity = \"all\"  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.2\n",
      "0.9.0\n"
     ]
    }
   ],
   "source": [
    "# check what version of numpy and other packages I have installed.\n",
    "print(pd.__version__)\n",
    "print(sns.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructions.pdf   README.md          seaborn.png\n",
      "LICENSE            matplotliblogo.png tips-project.ipynb\n",
      "matplotliblogo.png seaborn.png\n",
      "ls: *.csv: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# checking what files I have in this folder\n",
    "!ls  # see what files are in this folder\n",
    "!ls *.png # checking for png files\n",
    "!ls *.csv # checking for csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 1: Description: Descriptive Statistics and plots to describe the tips dataset. \n",
    "\n",
    "The goal for part 1 is to provide a good summary of the tips dataset using statistics and plots.\n",
    "I will start by reading in the Tips dataset from the csv file and looking at the resulting pandas DataFrame object. First a little overview of the Tips dataset and where it came from. I may refer to the dataset as 'Tips' or 'tips' throughout this document. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"tipsdataset\"></a>\n",
    "## The Tips dataset\n",
    "\n",
    "The tips dataset is available in the [seaborn-data repository](https://github.com/mwaskom/seaborn-data) belonging to Michael Waskom - the creator of the [seaborn](https://seaborn.pydata.org/index.html) python data visualisation package. \n",
    "According to it's README document this repository exists only as a convenient target for the `seaborn.load_dataset` functions to download sample datasets from. The **tips** dataset is also built into the **seaborn** package and can be easily loaded using the seaborn `load_dataset` command. (`seaborn.load_dataset(\"tips\")`)\n",
    "It is one of several example datasets that are used in the documentation of the `seaborn` package to demonstrate the features and uses of the `seaborn` package.\n",
    "\n",
    "The tips dataset is available in csv format at the following URL: <https://github.com/mwaskom/seaborn-data/blob/master/tips.csv>.\n",
    "\n",
    "According to the [introduction to seaborn](https://seaborn.pydata.org/introduction.html#an-introduction-to-seaborn) many of it's examples use the *boring* Tips dataset!:\n",
    "> which is very boring but quite useful for demonstration. The tips dataset illustrates the “tidy” approach to organizing a dataset.\n",
    "\n",
    "[Tidy data](https://en.wikipedia.org/wiki/Tidy_data) is an alternate name for the common statistical form called a model matrix or data matrix which is a\n",
    "\n",
    ">A standard method of displaying a multivariate set of data is in the form of a data matrix in which rows correspond to sample individuals and columns to variables, so that the entry in the ith row and jth column gives the value of the jth variate as measured or observed on the ith individual.\n",
    "\n",
    "Hadley Wickham of RStudio [2] defined 'Tidy Data' as:\n",
    "\n",
    "> a standard way of mapping the meaning of a dataset to its structure. A dataset is messy or tidy depending on how rows, columns and tables are matched up with observations, variables and types. In tidy data:\n",
    "1. Each variable forms a column.\n",
    "2. Each observation forms a row.\n",
    "3. Each type of observational unit forms a table.\n",
    "\n",
    " \n",
    "The [tips csv file](http://vincentarelbundock.github.io/Rdatasets/csv/reshape2/tips.csv) is also available at the [Rdatasets website](https://vincentarelbundock.github.io/Rdatasets/) which is a large collection of datasets originally distributed alongside the statistical software environment R and some of its add-on packages for teaching and statistical software development purposes maintained by [Vincent Arel-Bundock](http://arelbundock.com).\n",
    "\n",
    "According to the [tips dataset documentation](http://vincentarelbundock.github.io/Rdatasets/doc/reshape2/tips.html), the **Tips** dataset is a data frame with 244 rows and 7 variables which represents some tipping data where one waiter recorded information about each tip he received over a period of a few months working in one restaurant. \n",
    "In all the waiter recorded 244 tips. The data was reported in a collection of case studies for business statistics (Bryant & Smith 1995).[1]\n",
    "\n",
    "The waiter collected several variables:\n",
    "\n",
    "### Variables\n",
    "\n",
    "- tip in dollars  \n",
    "- bill in dollars    \n",
    "- sex of the bill payer  \n",
    "- whether there were smokers in the party  \n",
    "- day of the week  \n",
    "- time of day  \n",
    "- size of the party  \n",
    "\n",
    "The Tips dataset follows the tidy dataset format which I will show below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading / Reading in the data file into Python\n",
    "<a id=\"loading\"></a>\n",
    "\n",
    "\n",
    "#### About the Tips dataset.\n",
    "The tips dataset is available as described above in csv format at the two urls : \n",
    "- Vincent Arel-Bundock's [Rdatasets website](https://vincentarelbundock.github.io/Rdatasets/) at <http://vincentarelbundock.github.io/Rdatasets/csv/reshape2/tips.csv> \n",
    "- The [seaborn-data repository](https://github.com/mwaskom/seaborn-data) at <https://github.com/mwaskom/seaborn-data/blob/master/tips.csv>. Here the csv data is actually displayed nicely to the screen in tabular format - to get a link for the raw csv file click the `raw` icon which dumps the raw csv file to the browser from where you can copy the url <https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv>.   \n",
    "  \n",
    "A CSV file is a file where the values are seperated by a comma `,` (comma separated values).\n",
    "\n",
    "The Python `pandas` library has several functions for reading tabular data into a DataFrame object. \n",
    "Data that is in csv format can be read into a pandas **DataFrame** object either from a csv file or from a URL using the [`read_csv`](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-read-csv-table) function. A pandas DataFrame is a 2 dimensional data structure with rows and columns that resembles a spreadsheet.\n",
    "\n",
    "The `pandas.read_csv()` function performs type inferrence to infer the type of data types in each column. A DataFrame can have mixed data types such as numeric, integer, string, boolean etc but each column will have only one data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tips dataset is a small dataset so the entire csv file can be read into python in one go without causing any problems.\n",
    "For larger datasets you could specify how many lines to read in using the `nrows` argument. This dataset is very easy to read in to pandas. I am using the csv data from the [seaborn-data repository](https://github.com/mwaskom/seaborn-data) mentioned earlier. \n",
    "\n",
    "The csv file at the [Rdatasets website](https://vincentarelbundock.github.io/Rdatasets/) has an extra column added to it which looks like an index starting from 1 and this could be treated as the row index by setting the `index_col` argument to be the first column of the csv file `index_col =0` or alternatively this column could be dropped by setting the `usecols` to return a subset of  the columns, for example: `usecols=[1,2,3,4,5,6,7])`.\n",
    "\n",
    "The [parsing options](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#parsing-options) on <https://pandas.pydata.org> shows all the common arguments used when reading in csv files using the pandas `read_csv` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # import pandas library\n",
    "\n",
    "csv_url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv'\n",
    "\n",
    "# using the attribute information as the column names\n",
    "col_names = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width','Class']\n",
    "\n",
    "df =  pd.read_csv(csv_url)  ## creata a DataFrame named df from reading in the csv file from a URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the DataFrame looks ok\n",
    "\n",
    "Having successfully read in the csv file into a pandas DataFrame object, we can now use the panda's `head` and `tail` functions to ensure the file has been read in and looks ok before exploring the DataFrame further below.\n",
    "As it is a very small file it can be quickly checked against the csv file source and all looks fine so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()  # look at the top 5 rows of the DataFrame df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>29.03</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>27.18</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>22.67</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>17.82</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>18.78</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_bill   tip     sex smoker   day    time  size\n",
       "239       29.03  5.92    Male     No   Sat  Dinner     3\n",
       "240       27.18  2.00  Female    Yes   Sat  Dinner     2\n",
       "241       22.67  2.00    Male    Yes   Sat  Dinner     2\n",
       "242       17.82  1.75    Male     No   Sat  Dinner     2\n",
       "243       18.78  3.00  Female     No  Thur  Dinner     2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail() # Look at the bottom 5 rows of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"exploring\"></a>\n",
    "## Exploring the tips dataset\n",
    "\n",
    "Having read in the dataset using the pandas `read_csv()` function I will look at the dataset using pandas and seaborn packages which work hand in hand for analysing datasets. The pandas library has many useful functions for looking at the dataframe object created from reading in the csv file. The dataset can be sliced and diced to look at subsets of the dataset, to look at certain variables in the different columns or to select different categories of the variables or other combinations of rows and columns. Summary statistics can be easily generated with pandas. While the pandas package can be used to plot the data, this is where the seaborn package shines.\n",
    "\n",
    "The following pandas functions can be used to get a good overview of the dataset read into the DataFrame object called `df`.\n",
    "- `df.head()` - return the first 5 rows of the dataframe object\n",
    "- `df.tail()` - return the the last 5 rows of the dataframe object\n",
    "- `df.dtype()` - the data types attributes for each column in the dataset\n",
    "- `df.index()` - the row labels of the dataframe.\n",
    "\n",
    "- `df.isna().sum()` returns boolean values which can be summed to get the number of missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function pandas.core.frame.DataFrame.isna(self)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.head # a dataframe method (<function pandas.core.generic.NDFrame.head(self, n=5)>)\n",
    "pd.DataFrame.dtypes# a dataframe attribute (<property at 0x11f650958>)\n",
    "pd.DataFrame.index # dataframe method. to show the index (row labels) of the datarame. (AxisProperty )\n",
    "pd.DataFrame.isna # function for checking how missing values in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of the tips DataFrame is  RangeIndex(start=0, stop=244, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(\"The index of the tips DataFrame: \", df.index) # the index of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dtypes in the dataframe are:\n",
      "\n",
      "total_bill    float64\n",
      "tip           float64\n",
      "sex            object\n",
      "smoker         object\n",
      "day            object\n",
      "time           object\n",
      "size            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"The dtypes in the dataframe are:\", end='\\n\\n')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here just messing around trying to print the columns and the dtypes under them.\n",
    "using the star operator * to unpack the sequence.\n",
    "It is not necessary - I just want to know how to do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are the columns:    total_bill   tip   sex   smoker   day   time   size\n",
      "         with data types:    float64   float64   object   object   object   object   int64\n"
     ]
    }
   ],
   "source": [
    "print(\"The following are the columns: \", *df.columns, sep=\"   \")\n",
    "print(\"         with data types: \", *df.dtypes, sep=\"   \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object     4\n",
      "float64    2\n",
      "int64      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes.value_counts() ) # how many types of variables in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column names\n",
    "When the 'tips' csv dataset was read in using `pandas.read_csv()` function, the column names were assigned using the first line of data in the csv file. This is the default treatment with `pandas.read_csv()` if you have not set a header row or provided column names. If you did want to provide different column names you need to set `header=None` in the `read_csv` function and then provide the names to use using the `names` argument, for example `names= 'col-name1', 'col-name2'` etc.\n",
    "\n",
    "~~A csv file may or may not have a header row that you can use as the names of the columns. If there is a header row, you can allow pandas to assign the columns names using the header row. Alternatively you can assign the column names yourself in one of a few ways, either by setting header=None or by providing a list of names to the read_csv function. names='col-name1', 'col-name2','col-name3' If you don't set a header row or provide the names yourself, then pandas will just treat the first line of the data as the names of the columns~~\n",
    "\n",
    "The top of the dataframe shows that there are 7 columns as expected and an index that begins at 0 for the first row. If the index of a DataFrame is not set to a particular column or some other value, it will default to a sequence of integers beginning at 0 which is fine for the Tips dataset.  \n",
    "The index has been set to a range of integers from 0 (for the first row) up to 243 for the last row or observation in the dataset.\n",
    "~~You can set your own `index_col`  to the column numbers or names to use as the row index but I don't see any suitable column for an index. ~~\n",
    "\n",
    "The bottom of the dataset shows no surprises either. The tail function is useful for making sure a dataset has been read in properly as any problems in reading in csv files usually throw out the end of the dataframe. Here I can see the same types of values in each column, the last index is 243 so this means there must be 244 rows of observations in the dataset. \n",
    "\n",
    "There are 244 observations in the dataset. The index is a range of integers from 0 up to but not including 244. \n",
    "\n",
    "Check to see if there are any missing values or NA's in the dataset. `isna()` returns a boolean value of True or False, these are then summed to give a count of the missing values across the different columns.\n",
    "\n",
    "`dtypes` - the data types are inferred by the read_csv function. It is also possible to pass the data type when reading in the file. The data types show that there are three numerical columns and 4 non-numerical object columns. \n",
    "\n",
    "The read_csv() function performs type inferrence when reading in the dataset from the csv file. total_bill and tip are floats while size is an integer. The remaining columns have been read in as objects. As far as I now object is used for strings or when there are mixed data types in a column. The time column here is not an actual time but instead just a categorical variable.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "Pandas `describe` can be used to give a good summary of the numerical variables of the dataframe including, the count, the mean, the standard deviation, the minimum and maximum values, the median etc.\n",
    "\n",
    "`50%` is the median value which is where half the values are above this and half the values are below. The median is the average of the 2 middle values in the dataset taking in order of magnitude.\n",
    "`25%` is similar in that it shows the value of which 25% of the values are below this.  It is like taking the median of the bottom half of the dataset if ordered by magnitude. \n",
    "`75%` is similar idea - like the median of the top half of the dataset. \n",
    "The mean value is the average value in the dataset but it may not be typical of the values in the dataset, as it is could be the average over very small or very large values. \n",
    "The median is more like a typical value in the dataset or closer to some of the typical values. \n",
    "Look to see if the mean and median are similar or are much different from each other.\n",
    "If the median and mean are similar then the dataset is probably more balanced. \n",
    "\n",
    "`df.mean()`\n",
    "\n",
    "df.loc[df.loc[:,'sex']=='Female']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, you can take summary statistics of subsections of the dataset.\n",
    "\n",
    "For this dataset I could look at the statistics by sex and see if males or females pay similar type of tips or not, by day of the week to see if tips vary much from one day to another or from a weekday to the weekend or by time of the day. Whether a smoker or non-smoker is more inclined to leave a larger or a smaller tip.\n",
    "Part 2 question looks at the relationship between tip amount and total bill amount so I will leave that for now.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accessing data from the dataframe for calculating summary statistics on.\n",
    "\n",
    "some useful ones are to sort, filter, boolean selection etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the dataframe to see the type of values at the top and bottom of the dataset. Can sort in ascending order to see lowest values of a variable or combination of variable such as by tip amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='tip').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='tip', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'sex'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting using boolean values and then getting summary statistics.\n",
    "Can see the summary statistics by male or by females.\n",
    "by smoker or non-smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.loc[:, 'sex'] == 'Male'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.loc[:, 'smoker'] == 'Yes'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.loc[:, 'smoker'] == 'No'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.time=='Dinner'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.loc[:, 'sex'] == 'Female'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **groupby** to get counts by group\n",
    "There are three categorical variables: sex, smoker and day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"day\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"sex\",\"smoker\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"day\",\"sex\",\"smoker\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here experimenting with adding new columns to the dataframe based on other columns using the `np.where` function.\n",
    "\n",
    "https://stackoverflow.com/questions/36603018/pandas-multiple-conditions-based-on-multiple-columns-using-np-where/36603238\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean'] = np.where(df['tip']<=2 , 'yes', 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['weekend'] = np.where(((df.day == 'Sun') | (df.day == 'Sat') | (df.day == 'Fri')), 'weekend', 'weekday')\n",
    "\n",
    "df['mean'] = np.where(((df.tip <3) & ((df.smoker == 'yes'))), 'a mean smoker', 'not a mean smoker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"mean\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualising\"></a>\n",
    "## Visualing the tips dataset\n",
    "\n",
    "#### Seaborn plots of the tips dataset\n",
    "Having used pandas functions above to select subsets of the dataset, the **seaborn** package can be used to create some nicer visualisations than the basic plots in pandas and matplotlib. The **seaborn** library works with with **pandas**. It is built on top of **matplotlib** and closely integrated with **pandas** data structures.\n",
    "\n",
    "Whatever way the plots are created, they can be used to verify the numbers from the summary statistics. \n",
    "The plots will visualise any obvious relationships between the variables and also if there are any groups of observations that are clearly seperate to other groups of observations. \n",
    " \n",
    "The `pairplot` function in seaborn show scatter plots of the variables against each other. A kernel density function or histogram is displayed down the diagonal. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example plot of tips dataset as used in the official Introduction to seaborn guide using the built-in tips dataset.\n",
    "\n",
    "Using one of the examples in the seaborn documentation to draw a faceted scatter plot with multiple semantic variables\n",
    "\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "sns.relplot(x=\"total_bill\", y=\"tip\", col=\"time\",\n",
    "            hue=\"smoker\", style=\"smoker\", size=\"size\",\n",
    "            data=tips)\n",
    "This plot shows the relationship between five variables in the tips dataset. The two numeric variables (total_bill and tip) determined the position of each point on the axes, and the third (size) determined the size of each point. One categorical variable split the dataset onto two different axes (facets), and the other determined the color and shape of each point.\n",
    "\n",
    "This plot required only a single call to the seaborn function relplot(). Seaborn\n",
    "\n",
    "aims to make visualization a central part of exploring and understanding data. Its dataset-oriented plotting functions operate on dataframes and arrays containing whole datasets and internally perform the necessary semantic mapping and statistical aggregation to produce informative plots.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(df, hue = \"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue = \"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.plot(subplots=True, figsize=(12,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what do the plots show at a glance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More male than female bill-payers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(\"sex\",  data =df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More non-smokers than smokers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(\"smoker\",  data =df, hue =\"sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### significantly more male billpayers on saturday and sunday. \n",
    "On Thursdays and Fridays nearly the same number of male and female bill-payers.\n",
    "There does not seem to be any data for Mondays, Tuesdays and Wednesdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(\"day\",  data =df, hue =\"sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### far more non-smokers on sundays and thursdays but more smokers on Friday's\n",
    "Maybe after work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(\"day\",  data =df, hue=\"smoker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"total_bill\", y=\"tip\", col=\"time\",\n",
    "            hue=\"smoker\", style=\"smoker\", size=\"size\",\n",
    "            data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"day\", y=\"total_bill\", hue=\"smoker\",\n",
    "            kind=\"swarm\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"day\", y=\"tip\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### histograms and kernel density function of tip and total_bill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['tip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['total_bill'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 2 Regression: Discuss and analyse whether there is a relationship between the total bill and tip amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 3 Analysis: Analyse the relationship between the variables within the dataset.\n",
    "Analyse all pairs of variables or just a subset of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"references\"></a>\n",
    "# References\n",
    "\n",
    "### The Tips dataset\n",
    "- [1] Bryant, P. G. and Smith, M (1995) Practical Data Analysis: Case Studies in Business Statistics. Homewood, IL: Richard D. Irwin Publishing.\n",
    "- [2][Tidy Data by Hadley Wickham](https://vita.had.co.nz/papers/tidy-data.pdf)\n",
    "\n",
    "# References\n",
    "- **[Python.org](https://www.python.org/)**  \n",
    "- **[GitHub guides - Mastering Markdown](https://guides.github.com/features/mastering-markdown/)**  \n",
    "- **[Project Jupyter](https://jupyter.org/)**  \n",
    "- **[seaborn.pydata.org](https://seaborn.pydata.org/)**  \n",
    "- **[tips dataset on Michael Waskon GitHub](https://github.com/mwaskom/seaborn-data/blob/master/tips.csv.)**  \n",
    "- **[The R Datasets](http://vincentarelbundock.github.io/Rdatasets/datasets.html)** - including the tips dataset\n",
    "- **[seaborn](https://seaborn.pydata.org/introduction.html#introduction)**  \n",
    "- **[ipython magic commands ](https://ipython.readthedocs.io/en/stable/interactive/magics.html)**  \n",
    "\n",
    "### Python, GitHub and Jupyter resources\n",
    "- [python.org](https://docs.python.org/3/library/index.html)\n",
    "- Python for Data Analysis - Chapter 4 NumPy Basics: Arrays and Vectorised Computation by Wes McKinney\n",
    "- [Python Data Science Handbook by Jake VanderPlas ](https://jakevdp.github.io/PythonDataScienceHandbook/) \n",
    "- [Jake VanderPlas Website](http://vanderplas.com)\n",
    "- [numpy quickstart tutorial](https://numpy.org/devdocs/user/quickstart.html)\n",
    "\n",
    "\n",
    "- [GitHub Flavoured Markdown](https://github.github.com/gfm/)\n",
    "- [Jupyter Notebook documentation](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html#basic-workflow)\n",
    "- [Jupyter Notebook Tips, Tricks, and Shortcuts](https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/)\n",
    "- [python random docs](https://docs.python.org/3/library/random.html#module-random)\n",
    "-[LaTeX equations in Jupyter](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html#LaTeX-equations)\n",
    "- [pythonprogramming.net](https://pythonprogramming.net)\n",
    "\n",
    "- Jupyter logo.  Cameron Oelsen [BSD (http://opensource.org/licenses/bsd-license.php)]\n",
    "[toc](#toc)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning some markdown and magic commands to run in the Jupyter notebook \n",
    "\n",
    "\n",
    "### learning latex... \n",
    "\n",
    "see cheat sheet at [www.nyu.edu](https://www.nyu.edu/projects/beber/files/Chang_LaTeX_sheet.pdf)\n",
    "or [wch.github.io](https://wch.github.io/latexsheet/latexsheet-0.png)\n",
    "\n",
    "\n",
    "$e^{i\\pi} + 1 = 0$\n",
    "$$e^x=\\sum_{i=0}^\\infty \\frac{1}{i!}x^i$$\n",
    "\n",
    "$\\sigma$\n",
    "$$\\sigma$$\n",
    "$\\mu$\n",
    "\n",
    "x~  $N(\\mu,\\sigma^2)$\n",
    "\n",
    "### images\n",
    "to resize the image, I need to use html instead of markdown and use a css style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
